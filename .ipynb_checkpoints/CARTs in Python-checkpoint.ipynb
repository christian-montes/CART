{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 02 CARTs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating the paths to load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_path=os.path.join('data','wildfires_train.csv')\n",
    "testing_path=os.path.join('data','wildfires_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the data sets and joining them with the pd.concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dat=pd.read_csv(training_path)\n",
    "testing_dat=pd.read_csv(testing_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.concat takes a list of data frames\n",
    "# wildfires=pd.concat([training_dat, testing_dat]) // no reason to concatenate them; misunderstood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>temp</th>\n",
       "      <th>humidity</th>\n",
       "      <th>windspd</th>\n",
       "      <th>winddir</th>\n",
       "      <th>rain</th>\n",
       "      <th>days</th>\n",
       "      <th>vulnerable</th>\n",
       "      <th>other</th>\n",
       "      <th>ranger</th>\n",
       "      <th>pre1950</th>\n",
       "      <th>heli</th>\n",
       "      <th>resources</th>\n",
       "      <th>traffic</th>\n",
       "      <th>burned</th>\n",
       "      <th>wlf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>7.834467</td>\n",
       "      <td>8.306801</td>\n",
       "      <td>99.506964</td>\n",
       "      <td>65.940704</td>\n",
       "      <td>7.614523</td>\n",
       "      <td>W</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>127</td>\n",
       "      <td>1157.377161</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>117.067076</td>\n",
       "      <td>med</td>\n",
       "      <td>791.620319</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.694922</td>\n",
       "      <td>3.551933</td>\n",
       "      <td>69.887657</td>\n",
       "      <td>31.895045</td>\n",
       "      <td>6.534184</td>\n",
       "      <td>E</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>115</td>\n",
       "      <td>1134.429689</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>127.598019</td>\n",
       "      <td>hi</td>\n",
       "      <td>451.951898</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>6.498186</td>\n",
       "      <td>4.106111</td>\n",
       "      <td>91.152930</td>\n",
       "      <td>57.606073</td>\n",
       "      <td>11.580965</td>\n",
       "      <td>SE</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>119</td>\n",
       "      <td>1209.603068</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>132.273679</td>\n",
       "      <td>hi</td>\n",
       "      <td>584.451361</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>8.750841</td>\n",
       "      <td>8.887995</td>\n",
       "      <td>54.360593</td>\n",
       "      <td>46.166720</td>\n",
       "      <td>15.383351</td>\n",
       "      <td>E</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>112</td>\n",
       "      <td>1118.691631</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>116.482609</td>\n",
       "      <td>hi</td>\n",
       "      <td>589.681584</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>9.200210</td>\n",
       "      <td>9.810147</td>\n",
       "      <td>77.442791</td>\n",
       "      <td>25.490945</td>\n",
       "      <td>7.096639</td>\n",
       "      <td>NW</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>146</td>\n",
       "      <td>1319.237687</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>136.521750</td>\n",
       "      <td>lo</td>\n",
       "      <td>1010.567058</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          x         y       temp   humidity    windspd winddir      rain  \\\n",
       "0  7.834467  8.306801  99.506964  65.940704   7.614523       W  0.000037   \n",
       "1  2.694922  3.551933  69.887657  31.895045   6.534184       E  0.000040   \n",
       "2  6.498186  4.106111  91.152930  57.606073  11.580965      SE  0.000041   \n",
       "3  8.750841  8.887995  54.360593  46.166720  15.383351       E  0.000040   \n",
       "4  9.200210  9.810147  77.442791  25.490945   7.096639      NW  0.000045   \n",
       "\n",
       "   days   vulnerable  other  ranger  pre1950  heli   resources traffic  \\\n",
       "0   127  1157.377161      0       0        1     0  117.067076     med   \n",
       "1   115  1134.429689      0       1        0     1  127.598019      hi   \n",
       "2   119  1209.603068      0       0        0     1  132.273679      hi   \n",
       "3   112  1118.691631      0       0        0     0  116.482609      hi   \n",
       "4   146  1319.237687      0       0        1     0  136.521750      lo   \n",
       "\n",
       "        burned  wlf  \n",
       "0   791.620319    0  \n",
       "1   451.951898    0  \n",
       "2   584.451361    1  \n",
       "3   589.681584    1  \n",
       "4  1010.567058    0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_dat.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the first few rows of the data set, we can see that most of the attributes are numerical and only 'winddir', 'traffic', and 'wlf' are categorical. However, 'wlf' will not be used in this analysis.\n",
    "\n",
    "I will need to transform the attributes appropriately by building a pipeline using Column Transformer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(350, 17)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_dat.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training data set only has 350 observations but 17 attributes. Will most likely use 5-fold CV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "x             0\n",
       "y             0\n",
       "temp          0\n",
       "humidity      0\n",
       "windspd       0\n",
       "winddir       0\n",
       "rain          0\n",
       "days          0\n",
       "vulnerable    0\n",
       "other         0\n",
       "ranger        0\n",
       "pre1950       0\n",
       "heli          0\n",
       "resources     0\n",
       "traffic       0\n",
       "burned        0\n",
       "wlf           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking for missingness in the data\n",
    "training_dat.isna().aggregate('sum')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see that the data is in a tidy format. Since there is no missingness in the data, we can apply transformers to the data to fit models onto it. The data is already split into training and testing data.\n",
    "\n",
    "#### Transforming data using Sci-Kit Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first argument is the data set, then the test_size, then the random_state\n",
    "# wildfires_train, wildfires_test=train_test_split(wildfires, test_size=0.2, random_state=21)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will use the Sci-Kit Learn simple imputer to account for any missingness in future data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "one_hot_encoder=OneHotEncoder()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will seperate the data into the predictors and the response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dat=training_dat.drop('wlf', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=training_dat.drop('burned', axis=1)\n",
    "y_train=training_dat['burned'].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I will build a pipeline that will impute median for future missing values as well as one hot encode categorical variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_pipeline=Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median'))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I need to specify the columns that will go into each pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_num=x_train.drop(['winddir', 'traffic'], axis='columns')\n",
    "\n",
    "# this creates the list that will be fed into the Column Transformer\n",
    "num_attribs=list(train_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Categorical attributes will be for One Hot Encoding; will create the Categorical pipeline as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_attribs=['winddir', 'traffic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "full_pipeline=ColumnTransformer([\n",
    "    ('num', numerical_pipeline, num_attribs),\n",
    "    ('categorical', one_hot_encoder, cat_attribs)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating the clean data that will be fed into the algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_prepared=full_pipeline.fit_transform(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that I have the data prepared, I will use a Bagging Classifier in to predict number of hectares burned by the fire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_regressor=BaggingRegressor(DecisionTreeRegressor(),\n",
    "                               n_estimators=500, # this tells BaggingClassifier to make 500 DecisionTrees\n",
    "                               max_samples=1, # this is the default value; what percent of data to sample each time\n",
    "                               bootstrap=True,\n",
    "                               n_jobs=-1 # this tells the alg to use all available cores\n",
    "                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaggingRegressor(base_estimator=DecisionTreeRegressor(criterion='mse',\n",
       "                                                      max_depth=None,\n",
       "                                                      max_features=None,\n",
       "                                                      max_leaf_nodes=None,\n",
       "                                                      min_impurity_decrease=0.0,\n",
       "                                                      min_impurity_split=None,\n",
       "                                                      min_samples_leaf=1,\n",
       "                                                      min_samples_split=2,\n",
       "                                                      min_weight_fraction_leaf=0.0,\n",
       "                                                      presort=False,\n",
       "                                                      random_state=None,\n",
       "                                                      splitter='best'),\n",
       "                 bootstrap=True, bootstrap_features=False, max_features=1.0,\n",
       "                 max_samples=1, n_estimators=500, n_jobs=-1, oob_score=False,\n",
       "                 random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_regressor.fit(x_train_prepared, y_train) # make sure to feed the prepared data onto the algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to avoid overfitting the tree to the data, one can increase the parameters that start with min_* and decrease the default value of those that begin with max_*.\n",
    "\n",
    "The method above, however, does not implement cross validation. We can use sklearn.model_selection.cross_val_predict to make use of the entire training data to get predictions on the fold of data that was held out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The parameters that are passed into cross validate predict must be in the form of a dictionary. They will then be passed on to the estimator that is defined.\n",
    "\n",
    "This class outputs a n-dimensional array of predictions the same length as the data passed into it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining the dictionary of parameters that will be passed into cv predict\n",
    "parameters={\n",
    "    'n_estimators':500, # default value is 10\n",
    "    'max_samples':1, # this is the default value of the class\n",
    "    'bootstrap':True,\n",
    "    'n_jobs':-1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "bagging_reg_predict=BaggingRegressor(DecisionTreeRegressor(),\n",
    "                                     n_estimators=500, # this tells BaggingClassifier to make 500 DecisionTrees\n",
    "                                     max_samples=1,\n",
    "                                     bootstrap=True,\n",
    "                                     n_jobs=-1,\n",
    "                                     random_state=402)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_predict=cross_val_predict(bagging_reg_predict,\n",
    "                                 x_train_prepared,\n",
    "                                 y_train,\n",
    "                                 cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>675.790317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>675.790317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>675.790317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>675.790317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>675.790317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>345</td>\n",
       "      <td>714.711354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>346</td>\n",
       "      <td>714.711354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>347</td>\n",
       "      <td>714.711354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>348</td>\n",
       "      <td>714.711354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>349</td>\n",
       "      <td>714.711354</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>350 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0\n",
       "0    675.790317\n",
       "1    675.790317\n",
       "2    675.790317\n",
       "3    675.790317\n",
       "4    675.790317\n",
       "..          ...\n",
       "345  714.711354\n",
       "346  714.711354\n",
       "347  714.711354\n",
       "348  714.711354\n",
       "349  714.711354\n",
       "\n",
       "[350 rows x 1 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's see what y_train_predict looks like\n",
    "y_train_predict=pd.DataFrame(y_train_predict)\n",
    "y_train_predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I will combine the predicted and observed values to calculate the MSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>burned</th>\n",
       "      <th>burned_hat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>791.620319</td>\n",
       "      <td>675.790317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>451.951898</td>\n",
       "      <td>675.790317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>584.451361</td>\n",
       "      <td>675.790317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>589.681584</td>\n",
       "      <td>675.790317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1010.567058</td>\n",
       "      <td>675.790317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>345</td>\n",
       "      <td>509.784673</td>\n",
       "      <td>714.711354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>346</td>\n",
       "      <td>846.705612</td>\n",
       "      <td>714.711354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>347</td>\n",
       "      <td>610.056881</td>\n",
       "      <td>714.711354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>348</td>\n",
       "      <td>896.484081</td>\n",
       "      <td>714.711354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>349</td>\n",
       "      <td>744.254372</td>\n",
       "      <td>714.711354</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>350 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          burned  burned_hat\n",
       "0     791.620319  675.790317\n",
       "1     451.951898  675.790317\n",
       "2     584.451361  675.790317\n",
       "3     589.681584  675.790317\n",
       "4    1010.567058  675.790317\n",
       "..           ...         ...\n",
       "345   509.784673  714.711354\n",
       "346   846.705612  714.711354\n",
       "347   610.056881  714.711354\n",
       "348   896.484081  714.711354\n",
       "349   744.254372  714.711354\n",
       "\n",
       "[350 rows x 2 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_comp=pd.DataFrame(y_train)\n",
    "\n",
    "comp_data=pd.concat([y_train_comp, y_train_predict], axis=1)\n",
    "comp_data=comp_data.rename({0:'burned_hat'}, axis=1)\n",
    "comp_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88390.46456134808"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comp_data['squared_error']=(comp_data['burned'] - comp_data['burned_hat'])**2\n",
    "comp_data['squared_error'].agg('mean')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the mean squared error using cross validation for the **untuned** Bagging Regressor. Later on, I will tune this same model using a Random Grid Search method.\n",
    "\n",
    "To keep all the observations for each predictor, set `bootstrap=False` and `max_samples=1`. Sampling features and training instances is called the **Random Patches** method. This is done when `bootstrap_features=True` and `bootstrap=float`.\n",
    "\n",
    "By sampling features, we trade an increase in bias for a decrease in variance.\n",
    "\n",
    "### Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_regressor=RandomForestRegressor(n_estimators=500,\n",
    "                                  bootstrap=True,\n",
    "                                  oob_score=True,\n",
    "                                  random_state=402)\n",
    "\n",
    "y_rf_pred=cross_val_predict(rf_regressor,\n",
    "                           x_train_prepared,\n",
    "                           y_train,\n",
    "                           cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>718.999097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>563.665488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>704.792992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>525.139538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>921.579463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>345</td>\n",
       "      <td>544.614606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>346</td>\n",
       "      <td>748.036509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>347</td>\n",
       "      <td>629.764562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>348</td>\n",
       "      <td>744.130741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>349</td>\n",
       "      <td>704.368709</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>350 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0\n",
       "0    718.999097\n",
       "1    563.665488\n",
       "2    704.792992\n",
       "3    525.139538\n",
       "4    921.579463\n",
       "..          ...\n",
       "345  544.614606\n",
       "346  748.036509\n",
       "347  629.764562\n",
       "348  744.130741\n",
       "349  704.368709\n",
       "\n",
       "[350 rows x 1 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_rf_pred=pd.DataFrame(y_rf_pred)\n",
    "y_rf_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>burned</th>\n",
       "      <th>burned_hat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>791.620319</td>\n",
       "      <td>718.999097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>451.951898</td>\n",
       "      <td>563.665488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>584.451361</td>\n",
       "      <td>704.792992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>589.681584</td>\n",
       "      <td>525.139538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1010.567058</td>\n",
       "      <td>921.579463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>345</td>\n",
       "      <td>509.784673</td>\n",
       "      <td>544.614606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>346</td>\n",
       "      <td>846.705612</td>\n",
       "      <td>748.036509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>347</td>\n",
       "      <td>610.056881</td>\n",
       "      <td>629.764562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>348</td>\n",
       "      <td>896.484081</td>\n",
       "      <td>744.130741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>349</td>\n",
       "      <td>744.254372</td>\n",
       "      <td>704.368709</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>350 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          burned  burned_hat\n",
       "0     791.620319  718.999097\n",
       "1     451.951898  563.665488\n",
       "2     584.451361  704.792992\n",
       "3     589.681584  525.139538\n",
       "4    1010.567058  921.579463\n",
       "..           ...         ...\n",
       "345   509.784673  544.614606\n",
       "346   846.705612  748.036509\n",
       "347   610.056881  629.764562\n",
       "348   896.484081  744.130741\n",
       "349   744.254372  704.368709\n",
       "\n",
       "[350 rows x 2 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comp_rf=pd.concat([y_train_comp, y_rf_pred], axis=1)\n",
    "comp_rf=comp_rf.rename({0:'burned_hat'}, axis=1)\n",
    "comp_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8043.10963654247"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comp_rf['squared_error']=(comp_rf['burned'] - comp_rf['burned_hat']) ** 2\n",
    "comp_rf['squared_error'].agg('mean')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Random Forests MSE is much lower than the bagging model with both using 5-fold CV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
